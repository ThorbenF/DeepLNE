{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4403b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bussilab\n",
    "import plumed\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis import transformations\n",
    "from MDAnalysis.analysis import distances\n",
    "import MDAnalysis.analysis.distances as distances\n",
    "from MDAnalysis.analysis.base import AnalysisBase\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skmatter.feature_selection import FPS\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca40c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp /home/frohlkin@farma.unige.ch/Projects/PathOptimization/Toymodels/Dialanine/OneWayRatchet/Path1/diala.pdb .\n",
    "!scp /home/frohlkin@farma.unige.ch/Projects/PathOptimization/Toymodels/Dialanine/OneWayRatchet/Path1/topol.tpr .\n",
    "!scp /home/frohlkin@farma.unige.ch/Projects/PathOptimization/Toymodels/Dialanine/OneWayRatchet/Path1/newbox_diala_DESRES* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e7a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=[]\n",
    "lines.append('MOLINFO STRUCTURE=diala.pdb\\n')\n",
    "lines.append('phi: TORSION ATOMS=@phi-2\\n')\n",
    "lines.append('psi: TORSION ATOMS=@psi-2\\n')\n",
    "    \n",
    "lines.append('abmd: ABMD ARG=phi,psi TO=-2,2 KAPPA=5.0,5.0\\n')\n",
    "\n",
    "lines.append('COMMITTOR ...\\n')\n",
    "lines.append('   ARG=phi,psi\\n')\n",
    "lines.append('   STRIDE=1\\n')\n",
    "lines.append('   BASIN_LL1=-2.6,2.2\\n')\n",
    "lines.append('   BASIN_UL1=-2.5,2.5\\n')\n",
    "lines.append('...\\n')\n",
    "\n",
    "lines.append('PRINT FMT=%s STRIDE=1 FILE=COLVAR_getA ARG=* \\n' %('%8.4f'))\n",
    "\n",
    "f = open(\"plumed_getA.dat\", \"w\")\n",
    "for elem in lines:\n",
    "    f.writelines(elem)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mpirun -n 1 gmx_mpi mdrun -s topol -plumed plumed_getA.dat -deffnm getA -nsteps 50000000 -pin on -pinoffset 0 -nb gpu &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b285e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.62 should correspond to last frame (replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c514e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo 0| gmx_mpi trjconv -f getA.xtc -s newbox_diala_DESRES -dump 3.62 -o stateA.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960edcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_cutoff=2\n",
    "\n",
    "contact_ndx=range(1,22)\n",
    "sel=[(x,y) for x in contact_ndx for y in contact_ndx if abs(x - y) >= neighbor_cutoff]\n",
    "sel={tuple(sorted(item)) for item in sel}\n",
    "len(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28bae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    lines=[]\n",
    "    lines.append('MOLINFO STRUCTURE=diala.pdb\\n')\n",
    "    lines.append('phi: TORSION ATOMS=@phi-2\\n')\n",
    "    lines.append('psi: TORSION ATOMS=@psi-2\\n')\n",
    "\n",
    "    for e,elem in enumerate(sel):\n",
    "        lines.append('dist%s:  DISTANCE ATOMS=%s,%s \\n' %(e,elem[0],elem[1]))\n",
    "\n",
    "    lines.append('abmd: ABMD ARG=phi,psi TO=0.8,-1.0 KAPPA=8,4\\n')\n",
    "\n",
    "    lines.append('COMMITTOR ...\\n')\n",
    "    lines.append('   ARG=phi,psi\\n')\n",
    "    lines.append('   STRIDE=1\\n')\n",
    "    lines.append('   BASIN_LL1=0,-2\\n')\n",
    "    lines.append('   BASIN_UL1=1,-1\\n')\n",
    "    lines.append('...\\n')\n",
    "\n",
    "    lines.append('PRINT FMT=%s STRIDE=1 FILE=COLVAR_ratchet_path1_forward_%s ARG=* \\n' %('%8.4f',i))\n",
    "\n",
    "    f = open(\"plumed_ratchet_path1_forward_%s.dat\" %i, \"w\")\n",
    "    for elem in lines:\n",
    "        f.writelines(elem)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for j in 1 2 3 4 5\n",
    "do\n",
    "    mpirun -n 1 gmx_mpi mdrun -s topol -plumed plumed_ratchet_path1_forward_$j.dat -deffnm ratchet_path1_forward_$j -nsteps 50000000 -pin on -pinoffset 0 -nb gpu &\n",
    "    wait    \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_forward=[]\n",
    "psi_forward=[]\n",
    "\n",
    "for i in range(1,6):\n",
    "    \n",
    "    colvar_forward=plumed.read_as_pandas(\"COLVAR_ratchet_path1_forward_%s\" %i)\n",
    "    \n",
    "    print(len(colvar_forward['phi']))\n",
    "    phi_forward.append(colvar_forward['phi'])\n",
    "    psi_forward.append(colvar_forward['psi'])\n",
    "\n",
    "    data=np.load('raw_data/Dialanine/Dialanine_reference_FES.npy')\n",
    "\n",
    "phi_values = data[:,0]\n",
    "psi_values = data[:,1]\n",
    "file_free_values = data[:,2]\n",
    "\n",
    "phi_grid, psi_grid = np.meshgrid(np.linspace(phi_values.min(), phi_values.max(), 100),\n",
    "                                 np.linspace(psi_values.min(), psi_values.max(), 100))\n",
    "\n",
    "file_free_grid = griddata((phi_values, psi_values), file_free_values, (phi_grid, psi_grid), method='cubic')\n",
    "\n",
    "levels=np.arange(0,55,5)\n",
    "\n",
    "num_bins = 11\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(6,6), dpi=100)\n",
    "plt.contour(phi_grid, psi_grid,file_free_grid,levels,colors='grey')\n",
    "\n",
    "for i in range(1,6):\n",
    "    plt.scatter(phi_forward[i-1],psi_forward[i-1],c='black',s=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[]\n",
    "features_plot=[]\n",
    "\n",
    "for j in range(1,6):\n",
    "    colvar=plumed.read_as_pandas(\"COLVAR_ratchet_path1_forward_%s\"%j)\n",
    "    all_data_plot=colvar.iloc[:,1:3].to_numpy()\n",
    "    all_data=colvar.iloc[:,3:193].to_numpy()\n",
    "    features.append(all_data)\n",
    "    features_plot.append(all_data_plot)\n",
    "    print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4797f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batches=[]\n",
    "training_batches_plot=[]\n",
    "\n",
    "for j in range(1,6):\n",
    "        colvar=plumed.read_as_pandas(\"COLVAR_ratchet_path1_forward_%s\"%j)\n",
    "\n",
    "        data=np.array(colvar.iloc[:,1])\n",
    "        bins = [-4,2.2,4]\n",
    "        print(bins)\n",
    "\n",
    "        hist, bin_edges = np.histogram(data, bins=bins)\n",
    "\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "        all_data=np.vstack((colvar.iloc[:,1],colvar.iloc[:,2])).T\n",
    "        all_data_plot=colvar.iloc[:,1:3].to_numpy()\n",
    "        all_data=colvar.iloc[:,3:193].to_numpy()\n",
    "        print(all_data.shape)\n",
    "\n",
    "        min_propensity_bin = np.argmin(hist)\n",
    "\n",
    "        min_propensity_count = hist[min_propensity_bin]\n",
    "\n",
    "        print(min_propensity_count)\n",
    "\n",
    "        min_propensity_count= 300\n",
    "        temp =[]\n",
    "        temp_plot=[]\n",
    "        col_indices=[]\n",
    "        for i in range(len(bin_edges) - 1):\n",
    "            indices = np.where(np.logical_and(data >= bin_edges[i], data <= bin_edges[i+1]))[0]\n",
    "            \n",
    "            t_data=all_data[indices]\n",
    "            t_data_plot=all_data_plot[indices]\n",
    "            print(len(indices))\n",
    "            selector = FPS(n_to_select=min_propensity_count,initialize=0)\n",
    "            selector.fit(t_data.T)\n",
    "            selector.transform(t_data.T)\n",
    "            r_ndx=selector.selected_idx_\n",
    "            \n",
    "            col_indices.append(indices[r_ndx])\n",
    "        \n",
    "        temp_sorted_ndx=np.sort(np.concatenate(col_indices))\n",
    "        training_batches.append(all_data[temp_sorted_ndx])\n",
    "        training_batches_plot.append(all_data_plot[temp_sorted_ndx])\n",
    "\n",
    "training_datapoints=np.concatenate(training_batches)\n",
    "training_datapoints_plot=np.concatenate(training_batches_plot)\n",
    "print(training_datapoints.shape)\n",
    "plt.figure()\n",
    "\n",
    "for elem in training_batches_plot:\n",
    "    plt.scatter(elem[:,0], elem[:,1],alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bb976",
   "metadata": {},
   "outputs": [],
   "source": [
    "nneighbors=300\n",
    "\n",
    "bin_edges = [-4,1,2,4]\n",
    "\n",
    "min_propensity_count=nneighbors//(len(bin_edges)-1)\n",
    "\n",
    "data=training_datapoints_plot[:,0]\n",
    "col_indices=[]\n",
    "for i in range(len(bin_edges) - 1):\n",
    "    indices = np.where(np.logical_and(data >= bin_edges[i], data <= bin_edges[i+1]))[0]\n",
    "    \n",
    "    t_data=training_datapoints[indices]\n",
    "    t_data_plot=training_datapoints_plot[indices]\n",
    "    selector = FPS(n_to_select=min_propensity_count,initialize=0)\n",
    "    selector.fit(t_data.T)\n",
    "    selector.transform(t_data.T)\n",
    "    r_ndx=selector.selected_idx_\n",
    "    col_indices.append(indices[r_ndx])\n",
    "\n",
    "ndx=np.concatenate(col_indices)    \n",
    "neighbours=training_datapoints[ndx]\n",
    "neighbours_plot=training_datapoints_plot[ndx]\n",
    "\n",
    "print(neighbours.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(neighbours_plot[:,0],neighbours_plot[:,1],s=3,alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e915b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderCV(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                f: int,\n",
    "                d: int,\n",
    "                n: int,\n",
    "                ref: torch.Tensor,\n",
    "                act: str):\n",
    "        \n",
    "\n",
    "        super(AutoEncoderCV,self).__init__()\n",
    "        \n",
    "        # =======   LOSS  =======\n",
    "        # Reconstruction (MSE) loss\n",
    "        self.loss_mse = torch.nn.MSELoss()\n",
    "        \n",
    "\n",
    "        # ======= BLOCKS =======\n",
    "        \n",
    "        self.n_features=f\n",
    "        self.n_neighbors=n\n",
    "        self.d_metric=d\n",
    "        self.training_datapoints=ref\n",
    "        \n",
    "        self.mean=torch.mean(self.training_datapoints,axis=0)\n",
    "        self.std=torch.std(self.training_datapoints,axis=0)\n",
    "        self.range=(torch.max(self.training_datapoints,axis=0).values-torch.min(self.training_datapoints,axis=0).values)/2\n",
    "        \n",
    "        if act == 'ReLU':\n",
    "            self.activationf=torch.nn.ReLU()\n",
    "        if act == 'Tanh':\n",
    "            self.activationf=torch.nn.Tanh()\n",
    "        if act == 'Sigmoid':\n",
    "            self.activationf=torch.nn.Sigmoid()\n",
    "        if act == 'ELU':\n",
    "            self.activationf=torch.nn.ELU()\n",
    "        \n",
    "        self.metric = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(self.n_features, 50),\n",
    "                                    self.activationf,\n",
    "                                    torch.nn.Linear(50, 24),\n",
    "                                    self.activationf,\n",
    "                                    torch.nn.Linear(24, self.d_metric))\n",
    "            \n",
    "\n",
    "        # initialize encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "                                torch.nn.Linear(int(self.n_neighbors*self.d_metric), 24),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(24, 16),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(16, 1),\n",
    "                                torch.nn.Sigmoid())\n",
    "\n",
    "        # initialize decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "                                torch.nn.Linear(1, 16),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(16, 24),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(24, self.n_features))\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    def normalize(self,x: torch.Tensor)-> torch.Tensor:\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    def denormalize(self,x: torch.Tensor)-> torch.Tensor:\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def softmax_w(self,x: torch.Tensor, t=1e-1) -> torch.Tensor:\n",
    "        x = x / t\n",
    "        x = x - torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return (torch.exp(x)+1e-6) / torch.sum(torch.exp(x), dim=1, keepdim=True)\n",
    "        \n",
    "\n",
    "\n",
    "    def soft_top_k(self,x: torch.Tensor,t: torch.Tensor) -> torch.Tensor:\n",
    "        y = torch.zeros_like(x)\n",
    "        \n",
    "        x_w = x * (1 - y)\n",
    "        x_w_softmax = self.softmax_w(x_w)\n",
    "        y = y+x_w_softmax\n",
    "            \n",
    "        for k in range(self.n_neighbors):\n",
    "            x_w = x * (1 - y)\n",
    "            x_w_softmax = self.softmax_w(x_w)\n",
    "            y = y+x_w_softmax\n",
    "            \n",
    "            dm=torch.matmul(t.T,x_w_softmax.T)\n",
    "            \n",
    "            if k == 0:\n",
    "                dn=dm\n",
    "            else:\n",
    "                dn=torch.cat((dn,dm))\n",
    "        return dn.T\n",
    "\n",
    "    def learn_metric(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        d=self.metric(x)\n",
    "        t=self.metric(self.training_datapoints)\n",
    "        return d,t\n",
    "    \n",
    "    def find_nearest_neighbors(self,x: torch.Tensor,t: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        dist = torch.cdist(x, t)\n",
    "        dist=torch.exp(-dist)\n",
    "        dn = self.soft_top_k(dist,t)\n",
    "        \n",
    "        return dn\n",
    "        \n",
    "    def encode(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x=self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x=self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode_decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        #x_norm = x \n",
    "        x_norm = self.normalize(x) \n",
    "        d,t=self.learn_metric(x_norm)\n",
    "        dn=self.find_nearest_neighbors(d,t)\n",
    "        \n",
    "        s=self.encode(dn)\n",
    "        x_pre=self.decode(s) \n",
    "        x_hat = self.denormalize(x_pre) \n",
    "        \n",
    "        return x_hat,s,d,dn\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor :\n",
    "        #x_norm = x \n",
    "        x_norm = self.normalize(x) \n",
    "        d,t=self.learn_metric(x_norm)\n",
    "        dn=self.find_nearest_neighbors(d,t)\n",
    "        s=self.encode(dn).reshape(-1,1)\n",
    "        z=self.compute_z(x).reshape(-1,1)\n",
    "        \n",
    "        out=torch.hstack((s,z))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def compute_z(self,x: torch.Tensor,l=10) -> torch.Tensor:\n",
    "        x_hat,s,d,dn=model.encode_decode(training_datapoints)\n",
    "        z_dist=torch.cdist(x,x_hat)\n",
    "        z_dist=torch.absolute(z_dist)\n",
    "        z=(-1/l)*torch.log(torch.sum(torch.exp(-l*z_dist),axis=1))\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57273e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('training_datapoints_path1.npy',training_datapoints)\n",
    "np.save('training_datapoints_plot_path1.npy',training_datapoints_plot)\n",
    "np.save('neighbours_path1.npy',neighbours)\n",
    "\n",
    "training_datapoints=torch.Tensor(training_datapoints)\n",
    "neighbours=torch.Tensor(neighbours)\n",
    "\n",
    "n_features=190\n",
    "d_metric=3\n",
    "n_neighbors=3\n",
    "activation_function='Tanh' #'ReLU'\n",
    "\n",
    "model = AutoEncoderCV(f=n_features,d=d_metric,n=n_neighbors,ref=training_datapoints,act=activation_function)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "track=[]\n",
    "track_rec=[]\n",
    "track_equi =[]\n",
    "best_loss=1e10\n",
    "\n",
    "num_epochs = 5001\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_loss_rec = 0.0\n",
    "    train_loss_equi = 0.0\n",
    "    for data in training_batches:\n",
    "        x = torch.Tensor(data)\n",
    "        \n",
    "        # Forward Pass\n",
    "        x_hat,s,d,dn = model.encode_decode(x)\n",
    "\n",
    "        # Compute Loss\n",
    "        loss= model.loss_mse(x_hat, x)\n",
    "\n",
    "        # Backward Pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "        \n",
    "    train_loss = train_loss / len(training_batches)\n",
    "    \n",
    "    track.append(train_loss)\n",
    "    \n",
    "    if epoch%100==0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        \n",
    "        if train_loss < best_loss:\n",
    "            best_loss=train_loss\n",
    "            filename = 'model_DeepLNE_path1.pth'\n",
    "            torch.save(model, filename)  \n",
    "            torch.save(model.state_dict(), 'model_params_DeepLNE_path1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10476b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(track,'o-',color='orangered')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datapoints=np.load('training_datapoints_path1.npy')\n",
    "neighbours=np.load('neighbours_path1.npy')\n",
    "\n",
    "training_datapoints=torch.Tensor(training_datapoints)\n",
    "neighbours=torch.Tensor(neighbours)\n",
    "\n",
    "n_features=190\n",
    "d_metric=3\n",
    "n_neighbors=3\n",
    "activation_function='Tanh'\n",
    "\n",
    "model = AutoEncoderCV(f=n_features,d=d_metric,n=n_neighbors,ref=neighbours,act=activation_function)\n",
    "model.load_state_dict(torch.load('model_params_DeepLNE_path1.pt'), strict=False)\n",
    "\n",
    "neighbours_d=model.encode_decode(neighbours)[0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderCV_Speed(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                f: int,\n",
    "                d: int,\n",
    "                n: int,\n",
    "                ref: torch.Tensor,\n",
    "                ref_z: torch.Tensor,\n",
    "                act: str):\n",
    "        \n",
    "\n",
    "        super(AutoEncoderCV_Speed,self).__init__()\n",
    "        \n",
    "        # =======   LOSS  =======\n",
    "        # Reconstruction (MSE) loss\n",
    "        self.loss_mse = torch.nn.MSELoss()\n",
    "        \n",
    "\n",
    "        # ======= BLOCKS =======\n",
    "        \n",
    "        self.n_features=f\n",
    "        self.n_neighbors=n\n",
    "        self.d_metric=d\n",
    "        self.training_datapoints=ref\n",
    "        self.training_datapoints_z=ref_z\n",
    "        \n",
    "        self.mean=torch.mean(self.training_datapoints,axis=0)\n",
    "        self.std=torch.std(self.training_datapoints,axis=0)\n",
    "        self.range=(torch.max(self.training_datapoints,axis=0).values-torch.min(self.training_datapoints,axis=0).values)/2\n",
    "        \n",
    "        if act == 'ReLU':\n",
    "            self.activationf=torch.nn.ReLU()\n",
    "        if act == 'Tanh':\n",
    "            self.activationf=torch.nn.Tanh()\n",
    "        if act == 'Sigmoid':\n",
    "            self.activationf=torch.nn.Sigmoid()\n",
    "        if act == 'ELU':\n",
    "            self.activationf=torch.nn.ELU()\n",
    "        \n",
    "        self.metric = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(self.n_features, 50),\n",
    "                                    self.activationf,\n",
    "                                    torch.nn.Linear(50, 24),\n",
    "                                    self.activationf,\n",
    "                                    torch.nn.Linear(24, self.d_metric))\n",
    "            \n",
    "\n",
    "        # initialize encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "                                torch.nn.Linear(int(self.n_neighbors*self.d_metric), 24),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(24, 16),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(16, 1),\n",
    "                                torch.nn.Sigmoid())\n",
    "\n",
    "        # initialize decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "                                torch.nn.Linear(1, 16),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(16, 24),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(24, self.n_features))\n",
    "        \n",
    "\n",
    "    def normalize(self,x: torch.Tensor)-> torch.Tensor:\n",
    "        return x\n",
    "    \n",
    "    def denormalize(self,x: torch.Tensor)-> torch.Tensor:\n",
    "        return x\n",
    "    \n",
    "    def softmax_w(self,x: torch.Tensor, t=1e-1) -> torch.Tensor:\n",
    "        x = x / t\n",
    "        x = x - torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return (torch.exp(x)+1e-6) / torch.sum(torch.exp(x), dim=1, keepdim=True)\n",
    "        \n",
    "\n",
    "\n",
    "    def soft_top_k(self,x: torch.Tensor,t: torch.Tensor) -> torch.Tensor:\n",
    "        y = torch.zeros_like(x)\n",
    "        \n",
    "        x_w = x * (1 - y)\n",
    "        x_w_softmax = self.softmax_w(x_w)\n",
    "        y = y+x_w_softmax\n",
    "            \n",
    "        for k in range(self.n_neighbors):\n",
    "            x_w = x * (1 - y)\n",
    "            x_w_softmax = self.softmax_w(x_w)\n",
    "            y = y+x_w_softmax\n",
    "            \n",
    "            dm=torch.matmul(t.T,x_w_softmax.T)\n",
    "            \n",
    "            if k == 0:\n",
    "                dn=dm\n",
    "            else:\n",
    "                dn=torch.cat((dn,dm))\n",
    "        return dn.T\n",
    "\n",
    "    def learn_metric(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        d=self.metric(x)\n",
    "        t=self.metric(self.training_datapoints)\n",
    "        return d,t\n",
    "    \n",
    "    def find_nearest_neighbors(self,x: torch.Tensor,t: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        dist = torch.cdist(x, t)\n",
    "        dist=torch.exp(-dist)\n",
    "        dn = self.soft_top_k(dist,t)\n",
    "        \n",
    "        return dn\n",
    "        \n",
    "    def encode(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x=self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x=self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode_decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_norm = self.normalize(x) \n",
    "\n",
    "        d,t=self.learn_metric(x_norm)\n",
    "        dn=self.find_nearest_neighbors(d,t)\n",
    "        \n",
    "        s=self.encode(dn)\n",
    "        x_pre=self.decode(s) \n",
    "        x_hat = self.denormalize(x_pre) \n",
    "        \n",
    "        return x_hat,s,d,dn\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor :\n",
    "        x_norm = self.normalize(x) \n",
    "        d,t=self.learn_metric(x_norm)\n",
    "        dn=self.find_nearest_neighbors(d,t)\n",
    "        s=self.encode(dn).reshape(-1,1)\n",
    "        z=self.compute_z(x).reshape(-1,1)\n",
    "        \n",
    "        out=torch.hstack((s,z))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def compute_z(self,x: torch.Tensor,l=100) -> torch.Tensor:\n",
    "        z_dist=torch.cdist(x,self.training_datapoints_z)\n",
    "        z_dist=torch.absolute(z_dist)\n",
    "        z=(-1/l)*torch.log(torch.sum(torch.exp(-l*z_dist),axis=1))\n",
    "\n",
    "        return z\n",
    "\n",
    "model_speed = AutoEncoderCV_Speed(f=n_features,d=d_metric,n=n_neighbors,ref=neighbours,ref_z=neighbours_d,act=activation_function)\n",
    "model_speed.load_state_dict(torch.load('model_params_DeepLNE_path1.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_DeepLNE_path1.pth'\n",
    "torch.save(model_speed, filename)  \n",
    "torch.save(model_speed.state_dict(), 'model_params_DeepLNE_path1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a79c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input=training_datapoints\n",
    "\n",
    "out=model_speed(input)\n",
    "s=out[:,0]\n",
    "z=out[:,1]\n",
    "s=s.detach().numpy()\n",
    "z=z.detach().numpy()\n",
    "\n",
    "xhat=model_speed.encode_decode(input)[0].detach()\n",
    "\n",
    "ndx=np.where(z<0.2)[0] #find cutoff for harmonic constraint\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(training_datapoints_plot[ndx,0],training_datapoints_plot[ndx,1],c=s[ndx],alpha=1)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.scatter(training_datapoints_plot[ndx,0],training_datapoints_plot[ndx,1],c=z[ndx],alpha=1)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.scatter(training_datapoints_plot[ndx,0],s[ndx],c=z[ndx],alpha=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea5f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=torch.jit.trace(model_speed,torch.ones(1,n_features))\n",
    "m.save('model_DeepLNE_path1.ptc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c14679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "multiply_by_stddev = True #whether to multiply derivatives by std dev of inputs\n",
    "order_by_importance = True #plot results ordered by importance\n",
    "\n",
    "\n",
    "features=[]\n",
    "for j in range(1,6):\n",
    "    colvar=plumed.read_as_pandas(\"COLVAR_ratchet_path1_forward_%s\"%j)\n",
    "    all_data=colvar.iloc[::10,3:193].to_numpy()\n",
    "    features.append(all_data)\n",
    "    print(all_data.shape)\n",
    "    input_names = colvar.filter(regex='dist').columns.values\n",
    "    print(input_names,len(input_names))\n",
    "    \n",
    "    n_input = len(input_names)\n",
    "    in_num=np.arange(n_input)\n",
    "    rank=torch.zeros(n_input)\n",
    "    \n",
    "    X=features[j-1]\n",
    "    if multiply_by_stddev:\n",
    "        in_std=torch.std(torch.Tensor(X),axis=0).numpy()\n",
    "        \n",
    "    for iteration,x_i in enumerate(X):    \n",
    "        \n",
    "        x_i = torch.Tensor(x_i.reshape(1,-1))\n",
    "        x_i.requires_grad=True\n",
    "        s_i,z_i = model_speed(x_i)[0]\n",
    "        grad_i = torch.autograd.grad(s_i,x_i)\n",
    "        rank += grad_i[0].reshape(-1).abs()\n",
    "        \n",
    "        if iteration%100==0:\n",
    "            print(iteration)\n",
    "            \n",
    "    rank = rank.numpy()\n",
    "\n",
    "    if multiply_by_stddev:\n",
    "        rank = rank * in_std\n",
    "\n",
    "    #normalize to 1\n",
    "    rank/= np.sum(rank)\n",
    "\n",
    "    #sort\n",
    "    if order_by_importance:\n",
    "        index= rank.argsort()\n",
    "        input_names = input_names[index]\n",
    "        rank = rank[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig=plt.figure(figsize=(5,0.25*n_input), dpi=100)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "if order_by_importance:\n",
    "    ax.barh(in_num, rank,linewidth=0.3)\n",
    "    ax.set_yticklabels(input_names,fontsize=9)\n",
    "else:\n",
    "    ax.barh(in_num[::-1], rank[::-1],color='fessa1',edgecolor = 'fessa0',linewidth=0.3)\n",
    "    ax.set_yticklabels(input_names[::-1],fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Relevance')\n",
    "ax.set_ylabel('Inputs')\n",
    "ax.set_yticks(in_num)\n",
    "ax.yaxis.tick_right()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
