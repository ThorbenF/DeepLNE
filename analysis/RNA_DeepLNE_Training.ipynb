{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b5065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bussilab\n",
    "import plumed\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis import transformations\n",
    "from MDAnalysis.analysis import distances\n",
    "import MDAnalysis.analysis.distances as distances\n",
    "from MDAnalysis.analysis.base import AnalysisBase\n",
    "import nglview as ng\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skmatter.feature_selection import FPS\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dece0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtc_file = \"stateA.pdb\" \n",
    "u = mda.Universe(xtc_file)\n",
    "\n",
    "\n",
    "selected_atoms1=u.select_atoms(f\"resid 1 2 and name C* N* O*\")\n",
    "selected_atoms1 = selected_atoms1[selected_atoms1.types != '']\n",
    "selected_atoms2=u.select_atoms(f\"resid 7 8 and name C* N* O*\")\n",
    "selected_atoms2 = selected_atoms2[selected_atoms2.types != '']\n",
    "\n",
    "stem_pairs_stateA = []\n",
    "\n",
    "for i, atom1 in enumerate(selected_atoms1):\n",
    "    for atom2 in selected_atoms2:\n",
    "        distance = np.linalg.norm(atom1.position - atom2.position)\n",
    "        if distance < 5:\n",
    "            stem_pairs_stateA.append((atom1, atom2, distance))\n",
    "            \n",
    "print(len(stem_pairs_stateA))\n",
    "\n",
    "xtc_file = \"stateA.pdb\" \n",
    "u = mda.Universe(xtc_file)\n",
    "\n",
    "\n",
    "selected_atoms1=u.select_atoms(f\"resid 3 4 and name C* N* O*\")\n",
    "selected_atoms1 = selected_atoms1[selected_atoms1.types != '']\n",
    "selected_atoms2=u.select_atoms(f\"resid 5 6 and name C* N* O*\")\n",
    "selected_atoms2 = selected_atoms2[selected_atoms2.types != '']\n",
    "\n",
    "loop_pairs_stateA = []\n",
    "\n",
    "for i, atom1 in enumerate(selected_atoms1):\n",
    "    for atom2 in selected_atoms2:\n",
    "        distance = np.linalg.norm(atom1.position - atom2.position)\n",
    "        if distance < 3.5:\n",
    "            loop_pairs_stateA.append((atom1, atom2, distance))\n",
    "            \n",
    "print(len(loop_pairs_stateA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4848f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=[]\n",
    "lines.append('MOLINFO STRUCTURE=equilib_struct.pdb\\n')\n",
    "\n",
    "lines.append('eRMSD: ERMSD REFERENCE=GAGA_stateA.pdb ATOMS=@lcs-1,@lcs-2,@lcs-3,@lcs-4,@lcs-5,@lcs-6,@lcs-7,@lcs-8\\n')\n",
    "\n",
    "temp=[]\n",
    "for e,elem in enumerate(stem_pairs_stateA_id):\n",
    "    lines.append('s%s: COORDINATION GROUPA=%s GROUPB=%s SWITCH={RATIONAL R_0=0.5 NN=6 MM=8}\\n' %(e+1,elem[0],elem[1]))\n",
    "\n",
    "    temp.append('s%s' %(e+1))\n",
    "\n",
    "temp = ','.join(temp)              \n",
    "lines.append('stem_cmap: COMBINE ARG=%s PERIODIC=NO \\n' %temp)\n",
    "\n",
    "temp=[]\n",
    "for e,elem in enumerate(loop_pairs_stateA_id):\n",
    "    lines.append('l%s: COORDINATION GROUPA=%s GROUPB=%s SWITCH={RATIONAL R_0=0.35 NN=6 MM=8}\\n' %(e+1,elem[0],elem[1]))\n",
    "\n",
    "    temp.append('l%s' %(e+1))\n",
    "\n",
    "temp = ','.join(temp)              \n",
    "lines.append('loop_cmap: COMBINE ARG=%s PERIODIC=NO \\n' %temp)\n",
    "\n",
    "lines.append('abmd: ABMD ARG=eRMSD,stem_cmap,loop_cmap TO=3.0,-10.0,-10.0 KAPPA=100000.0,1.0,1.0\\n')\n",
    "\n",
    "lines.append('COMMITTOR ...\\n')\n",
    "lines.append('   ARG=eRMSD,stem_cmap\\n')\n",
    "lines.append('   STRIDE=100\\n')\n",
    "lines.append('   BASIN_LL1=2.1,0\\n')\n",
    "lines.append('   BASIN_UL1=2.5,3\\n')\n",
    "lines.append('...\\n')\n",
    "\n",
    "lines.append('PRINT FMT=%s STRIDE=100 FILE=COLVAR_getB ARG=* \\n' %('%8.4f'))\n",
    "\n",
    "f = open(\"plumed_getB.dat\", \"w\")\n",
    "for elem in lines:\n",
    "    f.writelines(elem)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3acaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "export OMP_NUM_THREADS=1\n",
    "mpirun -n 1 gmx_mpi mdrun -deffnm GetB -plumed plumed_getB.dat -pin on -pinoffset 0 -notunepme -nsteps 250000000 -nb gpu &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb146400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 6.2 with time at last frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f1abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo 0| gmx_mpi trjconv -f GetB.xtc -s equilib_struct.pdb -dump 6.2 -o stateB.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7712c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,16):\n",
    "    lines=[]\n",
    "    lines.append('MOLINFO STRUCTURE=equilib_struct.pdb\\n')\n",
    "\n",
    "    lines.append('eRMSD: ERMSD REFERENCE=GAGA_stateA.pdb ATOMS=@lcs-1,@lcs-2,@lcs-3,@lcs-4,@lcs-5,@lcs-6,@lcs-7,@lcs-8\\n')\n",
    "\n",
    "    temp=[]\n",
    "    for e,elem in enumerate(stem_pairs_stateA_id):\n",
    "        lines.append('s%s: COORDINATION GROUPA=%s GROUPB=%s SWITCH={RATIONAL R_0=0.5 NN=6 MM=8}\\n' %(e+1,elem[0],elem[1]))\n",
    "\n",
    "        temp.append('s%s' %(e+1))\n",
    "\n",
    "    temp = ','.join(temp)              \n",
    "    lines.append('stem_cmap: COMBINE ARG=%s PERIODIC=NO \\n' %temp)\n",
    "\n",
    "    temp=[]\n",
    "    for e,elem in enumerate(loop_pairs_stateA_id):\n",
    "        lines.append('l%s: COORDINATION GROUPA=%s GROUPB=%s SWITCH={RATIONAL R_0=0.35 NN=6 MM=8}\\n' %(e+1,elem[0],elem[1]))\n",
    "\n",
    "        temp.append('l%s' %(e+1))\n",
    "\n",
    "    temp = ','.join(temp)              \n",
    "    lines.append('loop_cmap: COMBINE ARG=%s PERIODIC=NO \\n' %temp)\n",
    "\n",
    "    lines.append('abmd: ABMD ARG=eRMSD,stem_cmap,loop_cmap TO=0.0,83.0,23.0 KAPPA=100000.0,0.1,0.1\\n')\n",
    "\n",
    "    lines.append('COMMITTOR ...\\n')\n",
    "    lines.append('   ARG=eRMSD\\n')\n",
    "    lines.append('   STRIDE=100\\n')\n",
    "    lines.append('   BASIN_LL1=0\\n')\n",
    "    lines.append('   BASIN_UL1=0.2\\n')\n",
    "    lines.append('...\\n')\n",
    "\n",
    "    lines.append('PRINT FMT=%s STRIDE=100 FILE=COLVAR_folding%s ARG=eRMSD,stem_cmap,loop_cmap \\n' %('%8.4f',i))\n",
    "\n",
    "    f = open(\"plumed_folding%s.dat\" %i, \"w\")\n",
    "    for elem in lines:\n",
    "        f.writelines(elem)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in {1..15};\n",
    "do\n",
    "export OMP_NUM_THREADS=1\n",
    "mpirun -n 1 gmx_mpi mdrun -deffnm Folding$i -plumed plumed_folding$i.dat -pin on -pinoffset $i -notunepme -nsteps 70000 -nb gpu &\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dff2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data=[]\n",
    "for i in range(1,16):\n",
    "    colvar_folding=plumed.read_as_pandas(\"COLVAR_folding%s\" %i)\n",
    "    \n",
    "    data.append([colvar_folding['eRMSD'],colvar_folding['stem_cmap']])\n",
    "    plt.scatter(data[i-1][0],data[i-1][1],s=10,label='%s' %i,alpha=0.2)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batches=[]\n",
    "\n",
    "for i in range(1,16)\n",
    "    \n",
    "    colvar_folding=plumed.read_as_pandas(\"COLVAR_folding%s\" %i)\n",
    "\n",
    "    t_data=colvar_folding.iloc[:,1:4].to_numpy()\n",
    "    selector = FPS(n_to_select=150,initialize=0)\n",
    "    selector.fit(t_data.T)\n",
    "    selector.transform(t_data.T)\n",
    "    r_ndx=selector.selected_idx_\n",
    "    training_batches.append(t_data[r_ndx])\n",
    "    \n",
    "    plt.scatter(t_data[r_ndx,0],t_data[r_ndx,1],s=3,alpha=0.5)\n",
    "    \n",
    "    print(training_batches[i-1].shape)\n",
    "training_datapoints=np.concatenate(training_batches)\n",
    "print(training_datapoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22fa95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nneighbors=300\n",
    "\n",
    "bin_edges = [0,1.7,3]\n",
    "\n",
    "min_propensity_count=nneighbors//(len(bin_edges)-1)\n",
    "\n",
    "min_propensity_count=[270,30]\n",
    "\n",
    "col_indices=[]\n",
    "for i in range(len(bin_edges) - 1):\n",
    "    indices = np.where(np.logical_and(training_datapoints[:,0] >= bin_edges[i], training_datapoints[:,0] <= bin_edges[i+1]))[0]\n",
    "    \n",
    "    t_data=training_datapoints[indices]\n",
    "    selector = FPS(n_to_select=min_propensity_count[i],initialize=0)\n",
    "    selector.fit(t_data.T)\n",
    "    selector.transform(t_data.T)\n",
    "    r_ndx=selector.selected_idx_\n",
    "    col_indices.append(indices[r_ndx])\n",
    "\n",
    "ndx=np.concatenate(col_indices)    \n",
    "neighbours=training_datapoints[ndx]\n",
    "\n",
    "print(neighbours.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(neighbours[:,0],neighbours[:,1],s=3,alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(neighbours[:,0],neighbours[:,2],s=3,alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(neighbours[:,1],neighbours[:,2],s=3,alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderCV(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                f: int,\n",
    "                d: int,\n",
    "                n: int,\n",
    "                ref: torch.Tensor,\n",
    "                act: str):\n",
    "        \n",
    "\n",
    "        super(AutoEncoderCV,self).__init__()\n",
    "        \n",
    "        # =======   LOSS  =======\n",
    "        # Reconstruction (MSE) loss\n",
    "        self.loss_mse = torch.nn.MSELoss()\n",
    "        \n",
    "\n",
    "        # ======= BLOCKS =======\n",
    "        \n",
    "        self.n_features=f\n",
    "        self.n_neighbors=n\n",
    "        self.d_metric=d\n",
    "        self.training_datapoints=ref\n",
    "        \n",
    "        self.mean=torch.mean(self.training_datapoints,axis=0)\n",
    "        self.std=torch.std(self.training_datapoints,axis=0)\n",
    "        self.range=(torch.max(self.training_datapoints,axis=0).values-torch.min(self.training_datapoints,axis=0).values)/2\n",
    "        \n",
    "        if act == 'ReLU':\n",
    "            self.activationf=torch.nn.ReLU()\n",
    "        if act == 'Tanh':\n",
    "            self.activationf=torch.nn.Tanh()\n",
    "        if act == 'Sigmoid':\n",
    "            self.activationf=torch.nn.Sigmoid()\n",
    "        if act == 'ELU':\n",
    "            self.activationf=torch.nn.ELU()\n",
    "        \n",
    "        self.metric = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(self.n_features, 24),\n",
    "                                    self.activationf,\n",
    "                                    torch.nn.Linear(24, 8),\n",
    "                                    self.activationf,\n",
    "                                    torch.nn.Linear(8, self.d_metric))\n",
    "            \n",
    "\n",
    "        # initialize encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "                                torch.nn.Linear(int(self.n_neighbors*self.d_metric), 24),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(24, 8),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(8, 1),\n",
    "                                torch.nn.Sigmoid())\n",
    "\n",
    "        # initialize decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "                                torch.nn.Linear(1, 8),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(8, 24),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(24, self.n_features))\n",
    "        \n",
    "    \n",
    "    def normalize(self,x: torch.Tensor)-> torch.Tensor:\n",
    "        return x\n",
    "    \n",
    "    def denormalize(self,x: torch.Tensor)-> torch.Tensor:\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def softmax_w(self,x: torch.Tensor, t=1e-1) -> torch.Tensor:\n",
    "        x = x / t\n",
    "        x = x - torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return (torch.exp(x)+1e-6) / torch.sum(torch.exp(x), dim=1, keepdim=True)\n",
    "        \n",
    "\n",
    "\n",
    "    def soft_top_k(self,x: torch.Tensor,t: torch.Tensor) -> torch.Tensor:\n",
    "        y = torch.zeros_like(x)\n",
    "        \n",
    "        x_w = x * (1 - y)\n",
    "        x_w_softmax = self.softmax_w(x_w)\n",
    "        y = y+x_w_softmax\n",
    "            \n",
    "        for k in range(self.n_neighbors):\n",
    "            x_w = x * (1 - y)\n",
    "            x_w_softmax = self.softmax_w(x_w)\n",
    "            y = y+x_w_softmax\n",
    "            \n",
    "            dm=torch.matmul(t.T,x_w_softmax.T)\n",
    "            \n",
    "            if k == 0:\n",
    "                dn=dm\n",
    "            else:\n",
    "                dn=torch.cat((dn,dm))\n",
    "        return dn.T\n",
    "\n",
    "    def learn_metric(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        d=self.metric(x)\n",
    "        t=self.metric(self.training_datapoints)\n",
    "        return d,t\n",
    "    \n",
    "    def find_nearest_neighbors(self,x: torch.Tensor,t: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        dist = torch.cdist(x, t)\n",
    "        dist=torch.exp(-dist)\n",
    "        dn = self.soft_top_k(dist,t)\n",
    "        \n",
    "        return dn\n",
    "        \n",
    "    def encode(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x=self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x=self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode_decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_norm = self.normalize(x) \n",
    "        d,t=self.learn_metric(x_norm)\n",
    "        dn=self.find_nearest_neighbors(d,t)\n",
    "        \n",
    "        s=self.encode(dn)\n",
    "        x_pre=self.decode(s) \n",
    "        x_hat = self.denormalize(x_pre) \n",
    "        \n",
    "        return x_hat,s,d,dn\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor :\n",
    "        x_norm = self.normalize(x) \n",
    "        d,t=self.learn_metric(x_norm)\n",
    "        dn=self.find_nearest_neighbors(d,t)\n",
    "        s=self.encode(dn).reshape(-1,1)\n",
    "        z=self.compute_z(x).reshape(-1,1)\n",
    "        \n",
    "        out=torch.hstack((s,z))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def compute_z(self,x: torch.Tensor,l=10) -> torch.Tensor:\n",
    "        x_hat,s,d,dn=model.encode_decode(training_datapoints)\n",
    "        z_dist=torch.cdist(x,x_hat)\n",
    "        z_dist=torch.absolute(z_dist)\n",
    "        z=(-1/l)*torch.log(torch.sum(torch.exp(-l*z_dist),axis=1))\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('training_datapoints.npy',training_datapoints)\n",
    "np.save('neighbours.npy',neighbours)\n",
    "\n",
    "training_datapoints=torch.Tensor(training_datapoints)\n",
    "neighbours=torch.Tensor(neighbours)\n",
    "\n",
    "n_features=3\n",
    "d_metric=3\n",
    "n_neighbors=3\n",
    "activation_function='Tanh'\n",
    "\n",
    "model = AutoEncoderCV(f=n_features,d=d_metric,n=n_neighbors,ref=training_datapoints,act=activation_function)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "track=[]\n",
    "track_rec=[]\n",
    "track_equi =[]\n",
    "best_loss=1e10\n",
    "\n",
    "num_epochs = 5001\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_loss_rec = 0.0\n",
    "    train_loss_equi = 0.0\n",
    "    for data in training_batches:\n",
    "        x = torch.Tensor(data)\n",
    "        \n",
    "        # Forward Pass\n",
    "        x_hat,s,d,dn = model.encode_decode(x)\n",
    "\n",
    "        # Compute Loss\n",
    "                \n",
    "        loss= model.loss_mse(x_hat, x)\n",
    "\n",
    "        # Backward Pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "        \n",
    "    train_loss = train_loss / len(training_batches)\n",
    "    \n",
    "    track.append(train_loss)\n",
    "    \n",
    "    if epoch%100==0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        \n",
    "        if train_loss < best_loss:\n",
    "            best_loss=train_loss\n",
    "            filename = 'model_DeepLNE.pth'\n",
    "            torch.save(model, filename)  \n",
    "            torch.save(model.state_dict(), 'model_params_DeepLNE.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(track,'o-',color='orangered')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datapoints=np.load('training_datapoints.npy')\n",
    "neighbours=np.load('neighbours.npy')\n",
    "\n",
    "training_datapoints=torch.Tensor(training_datapoints)\n",
    "neighbours=torch.Tensor(neighbours)\n",
    "\n",
    "n_features=3\n",
    "d_metric=3\n",
    "n_neighbors=3\n",
    "activation_function='Tanh'\n",
    "\n",
    "model = AutoEncoderCV(f=n_features,d=d_metric,n=n_neighbors,ref=neighbours,act=activation_function)\n",
    "model.load_state_dict(torch.load('model_params_DeepLNE.pt'), strict=False)\n",
    "\n",
    "neighbours_d=model.encode_decode(neighbours)[0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee605c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderCV_Speed(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                f: int,\n",
    "                d: int,\n",
    "                n: int,\n",
    "                ref: torch.Tensor,\n",
    "                ref_z: torch.Tensor,\n",
    "                act: str):\n",
    "        \n",
    "\n",
    "        super(AutoEncoderCV_Speed,self).__init__()\n",
    "        \n",
    "        # =======   LOSS  =======\n",
    "        # Reconstruction (MSE) loss\n",
    "        self.loss_mse = torch.nn.MSELoss()\n",
    "        \n",
    "\n",
    "        # ======= BLOCKS =======\n",
    "        \n",
    "        self.n_features=f\n",
    "        self.n_neighbors=n\n",
    "        self.d_metric=d\n",
    "        self.training_datapoints=ref\n",
    "        self.training_datapoints_z=ref_z\n",
    "        \n",
    "        self.mean=torch.mean(self.training_datapoints,axis=0)\n",
    "        self.std=torch.std(self.training_datapoints,axis=0)\n",
    "        self.range=(torch.max(self.training_datapoints,axis=0).values-torch.min(self.training_datapoints,axis=0).values)/2\n",
    "        \n",
    "        if act == 'ReLU':\n",
    "            self.activationf=torch.nn.ReLU()\n",
    "        if act == 'Tanh':\n",
    "            self.activationf=torch.nn.Tanh()\n",
    "        if act == 'Sigmoid':\n",
    "            self.activationf=torch.nn.Sigmoid()\n",
    "        if act == 'ELU':\n",
    "            self.activationf=torch.nn.ELU()\n",
    "        \n",
    "        self.metric = torch.nn.Sequential(\n",
    "                                    torch.nn.Linear(self.n_features, 24),\n",
    "                                    self.activationf,\n",
    "                                    torch.nn.Linear(24, 8),\n",
    "                                    self.activationf,\n",
    "                                    torch.nn.Linear(8, self.d_metric))\n",
    "            \n",
    "\n",
    "        # initialize encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "                                torch.nn.Linear(int(self.n_neighbors*self.d_metric), 24),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(24, 8),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(8, 1),\n",
    "                                torch.nn.Sigmoid())\n",
    "\n",
    "        # initialize decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "                                torch.nn.Linear(1, 8),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(8, 24),\n",
    "                                self.activationf,\n",
    "                                torch.nn.Linear(24, self.n_features))\n",
    "        \n",
    "\n",
    "    def normalize(self,x: torch.Tensor)-> torch.Tensor:\n",
    "        return x\n",
    "    \n",
    "    def denormalize(self,x: torch.Tensor)-> torch.Tensor:\n",
    "        return x\n",
    "    \n",
    "    def softmax_w(self,x: torch.Tensor, t=1e-1) -> torch.Tensor:\n",
    "        x = x / t\n",
    "        x = x - torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return (torch.exp(x)+1e-6) / torch.sum(torch.exp(x), dim=1, keepdim=True)\n",
    "        \n",
    "\n",
    "\n",
    "    def soft_top_k(self,x: torch.Tensor,t: torch.Tensor) -> torch.Tensor:\n",
    "        y = torch.zeros_like(x)\n",
    "        \n",
    "        x_w = x * (1 - y)\n",
    "        x_w_softmax = self.softmax_w(x_w)\n",
    "        y = y+x_w_softmax\n",
    "            \n",
    "        for k in range(self.n_neighbors):\n",
    "            x_w = x * (1 - y)\n",
    "            x_w_softmax = self.softmax_w(x_w)\n",
    "            y = y+x_w_softmax\n",
    "            \n",
    "            dm=torch.matmul(t.T,x_w_softmax.T)\n",
    "            \n",
    "            if k == 0:\n",
    "                dn=dm\n",
    "            else:\n",
    "                dn=torch.cat((dn,dm))\n",
    "        return dn.T\n",
    "\n",
    "    def learn_metric(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        d=self.metric(x)\n",
    "        t=self.metric(self.training_datapoints)\n",
    "        return d,t\n",
    "    \n",
    "    def find_nearest_neighbors(self,x: torch.Tensor,t: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        dist = torch.cdist(x, t)\n",
    "        dist=torch.exp(-dist)\n",
    "        dn = self.soft_top_k(dist,t)\n",
    "        \n",
    "        return dn\n",
    "        \n",
    "    def encode(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x=self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x=self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode_decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        x_norm = self.normalize(x) \n",
    "\n",
    "        d,t=self.learn_metric(x_norm)\n",
    "        dn=self.find_nearest_neighbors(d,t)\n",
    "        \n",
    "        s=self.encode(dn)\n",
    "        x_pre=self.decode(s) \n",
    "        x_hat = self.denormalize(x_pre) \n",
    "        \n",
    "        return x_hat,s,d,dn\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor :\n",
    "        x_norm = self.normalize(x) \n",
    "        d,t=self.learn_metric(x_norm)\n",
    "        dn=self.find_nearest_neighbors(d,t)\n",
    "        s=self.encode(dn).reshape(-1,1)\n",
    "        z=self.compute_z(x).reshape(-1,1)\n",
    "        \n",
    "        out=torch.hstack((s,z))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def compute_z(self,x: torch.Tensor,l=10) -> torch.Tensor:\n",
    "        z_dist=torch.cdist(x,self.training_datapoints_z)\n",
    "        z_dist=torch.absolute(z_dist)\n",
    "        z=(-1/l)*torch.log(torch.sum(torch.exp(-l*z_dist),axis=1))\n",
    "\n",
    "        return z\n",
    "\n",
    "model_speed = AutoEncoderCV_Speed(f=n_features,d=d_metric,n=n_neighbors,ref=neighbours,ref_z=neighbours_d,act=activation_function)\n",
    "model_speed.load_state_dict(torch.load('model_params_DeepLNE.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input=training_datapoints\n",
    "\n",
    "out=model_speed(input)\n",
    "s=out[:,0]\n",
    "z=out[:,1]\n",
    "s=s.detach().numpy()\n",
    "z=z.detach().numpy()\n",
    "\n",
    "xhat=model_speed.encode_decode(input)[0].detach()\n",
    "\n",
    "ndx=np.where(z<100000)[0] #choose value of z for harmonic constraint \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(training_datapoints[ndx,0],training_datapoints[ndx,1],c=s[ndx],alpha=1)\n",
    "plt.colorbar()\n",
    "plt.scatter(xhat[ndx,0],xhat[ndx,1],color='k',alpha=1)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.scatter(training_datapoints[ndx,0],training_datapoints[ndx,1],c=z[ndx],alpha=1)\n",
    "plt.colorbar()\n",
    "plt.scatter(xhat[ndx,0],xhat[ndx,1],color='k',alpha=1)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.scatter(training_datapoints[ndx,0],s[ndx],c=z[ndx],alpha=1)\n",
    "plt.colorbar()\n",
    "plt.scatter(xhat[ndx,0],s[ndx],color='k',alpha=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(training_datapoints[ndx,0],training_datapoints[ndx,2],c=s[ndx],alpha=1)\n",
    "plt.colorbar()\n",
    "plt.scatter(xhat[ndx,0],xhat[ndx,2],color='k',alpha=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(training_datapoints[ndx,1],training_datapoints[ndx,2],c=s[ndx],alpha=1)\n",
    "plt.colorbar()\n",
    "plt.scatter(xhat[ndx,1],xhat[ndx,2],color='k',alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=torch.jit.trace(model_speed,torch.ones(1,n_features))\n",
    "m.save('model_DeepLNE.ptc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2befb368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "multiply_by_stddev = True #whether to multiply derivatives by std dev of inputs\n",
    "order_by_importance = True #plot results ordered by importance\n",
    "\n",
    "\n",
    "features=[]\n",
    "\n",
    "for j in range(1,16):\n",
    "    colvar=plumed.read_as_pandas(\"COLVAR_folding%s\"%j)\n",
    "    all_data=colvar.iloc[:,1:4].to_numpy()\n",
    "    features.append(all_data)\n",
    "    #features_plot.append(all_data_plot)\n",
    "    print(all_data.shape)\n",
    "    input_names = np.array(['eRMSD','stem_cmap','loop_cmap'])\n",
    "    print(input_names,len(input_names))\n",
    "    \n",
    "    n_input = len(input_names)\n",
    "\n",
    "    #init arrays\n",
    "    in_num=np.arange(n_input)\n",
    "    rank=torch.zeros(n_input)\n",
    "    \n",
    "    X=features[j-1]\n",
    "    #compute input std dev\n",
    "    if multiply_by_stddev:\n",
    "        in_std=torch.std(torch.Tensor(X),axis=0).numpy()\n",
    "        \n",
    "    for iteration,x_i in enumerate(X):    \n",
    "        \n",
    "        x_i = torch.Tensor(x_i.reshape(1,-1))\n",
    "        x_i.requires_grad=True\n",
    "        # calculate cv \n",
    "        s_i,z_i = model_speed(x_i)[0]\n",
    "        # calculate derivatives\n",
    "        grad_i = torch.autograd.grad(s_i,x_i)\n",
    "        # accumulate them\n",
    "        #print(grad_i[0].shape)\n",
    "        rank += grad_i[0].reshape(-1).abs()\n",
    "        \n",
    "        if iteration%100==0:\n",
    "            print(iteration)\n",
    "            \n",
    "    rank = rank.numpy()\n",
    "\n",
    "    #multiply by std dev\n",
    "    if multiply_by_stddev:\n",
    "        rank = rank * in_std\n",
    "\n",
    "    #normalize to 1\n",
    "    rank/= np.sum(rank)\n",
    "\n",
    "    #sort\n",
    "    if order_by_importance:\n",
    "        index= rank.argsort()\n",
    "        input_names = input_names[index]\n",
    "        rank = rank[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig=plt.figure(figsize=(5,0.25*10), dpi=100)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "if order_by_importance:\n",
    "    ax.barh(in_num, rank,linewidth=0.3)\n",
    "    ax.set_yticklabels(input_names,fontsize=9)\n",
    "else:\n",
    "    ax.barh(in_num[::-1], rank[::-1],color='fessa1',edgecolor = 'fessa0',linewidth=0.3)\n",
    "    ax.set_yticklabels(input_names[::-1],fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Relevance')\n",
    "ax.set_ylabel('Inputs')\n",
    "ax.set_yticks(in_num)\n",
    "ax.yaxis.tick_right()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
