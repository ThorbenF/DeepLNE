{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f24f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeb4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLNE_CV(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                ANN_layers: list,\n",
    "                AutoEncoder_layers: list,\n",
    "                f: int,\n",
    "                d: int,\n",
    "                n: int,\n",
    "                ref: torch.Tensor,\n",
    "                ref_z: torch.Tensor,\n",
    "                act: str,\n",
    "                z_lambda: float):\n",
    "        \n",
    "\n",
    "        super(DeepLNE_CV,self).__init__()\n",
    "        \n",
    "        # =======   LOSS  =======\n",
    "        self.loss_mse = torch.nn.MSELoss()\n",
    "        \n",
    "\n",
    "        # ======= BLOCKS =======\n",
    "        \n",
    "        self.n_features=f\n",
    "        self.n_neighbors=n\n",
    "        self.d_metric=d\n",
    "        self.training_datapoints=ref\n",
    "        self.training_datapoints_z=ref_z\n",
    "        self.z_lambda=z_lambda\n",
    "        \n",
    "        print('Numer of input features:',self.n_features)\n",
    "        print('Numer of neighbors:',self.n_neighbors)\n",
    "        print('Dimension for nn search:',self.d_metric)\n",
    "         \n",
    "        if act == 'ReLU':\n",
    "            self.activationf=torch.nn.ReLU()\n",
    "        if act == 'Tanh':\n",
    "            self.activationf=torch.nn.Tanh()\n",
    "        if act == 'Sigmoid':\n",
    "            self.activationf=torch.nn.Sigmoid()\n",
    "        if act == 'ELU':\n",
    "            self.activationf=torch.nn.ELU()\n",
    "        \n",
    "        self.ANNlayers = []\n",
    "        \n",
    "        self.ANNlayers.append(torch.nn.Linear(self.n_features, ANN_layers[0]))\n",
    "        self.ANNlayers.append(self.activationf)\n",
    "        \n",
    "        for i in range(len(ANN_layers) - 1):\n",
    "            self.ANNlayers.append(torch.nn.Linear(ANN_layers[i], ANN_layers[i + 1]))\n",
    "            self.ANNlayers.append(self.activationf)\n",
    "\n",
    "        self.ANNlayers.append(torch.nn.Linear(ANN_layers[-1], self.d_metric))\n",
    "        \n",
    "        self.metric = torch.nn.Sequential(*self.ANNlayers)\n",
    "        print('ANN architecture: ',self.metric)\n",
    "            \n",
    "\n",
    "        # initialize encoder\n",
    "        self.AutoEncoderLayers = []\n",
    "        \n",
    "        self.AutoEncoderLayers.append(torch.nn.Linear(int(self.n_neighbors*self.d_metric), AutoEncoder_layers[0]))\n",
    "        self.AutoEncoderLayers.append(self.activationf)\n",
    "        \n",
    "        for i in range(len(AutoEncoder_layers) - 1):\n",
    "            self.AutoEncoderLayers.append(torch.nn.Linear(AutoEncoder_layers[i], AutoEncoder_layers[i + 1]))\n",
    "            self.AutoEncoderLayers.append(self.activationf)\n",
    "\n",
    "        self.AutoEncoderLayers.append(torch.nn.Linear(AutoEncoder_layers[-1], 1))\n",
    "        self.AutoEncoderLayers.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(*self.AutoEncoderLayers)\n",
    "        print('Encoder architecture: ',self.encoder)\n",
    "        \n",
    "        # initialize decoder\n",
    "        self.AutoDecoderLayers = []\n",
    "        AutoDecoder_layers=AutoEncoder_layers[::-1]\n",
    "        \n",
    "        self.AutoDecoderLayers.append(torch.nn.Linear(1, AutoDecoder_layers[0]))\n",
    "        self.AutoDecoderLayers.append(self.activationf)\n",
    "        \n",
    "        for i in range(len(AutoDecoder_layers) - 1):\n",
    "            self.AutoDecoderLayers.append(torch.nn.Linear(AutoDecoder_layers[i], AutoDecoder_layers[i + 1]))\n",
    "            self.AutoDecoderLayers.append(self.activationf)\n",
    "\n",
    "        self.AutoDecoderLayers.append(torch.nn.Linear(AutoDecoder_layers[-1], self.n_features))\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(*self.AutoDecoderLayers)\n",
    "        print('Decoder architecture: ',self.decoder)\n",
    "    \n",
    "    def softmax_w(self,x: torch.Tensor, t=1e-1) -> torch.Tensor:\n",
    "        x = x / t\n",
    "        x = x - torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return (torch.exp(x)+1e-4) / torch.sum(torch.exp(x), dim=1, keepdim=True)\n",
    "        \n",
    "\n",
    "    def soft_top_k(self,x: torch.Tensor,t: torch.Tensor) -> torch.Tensor:\n",
    "        y = torch.zeros_like(x)\n",
    "        \n",
    "        x_w = x * (1 - y)\n",
    "        x_w_softmax = self.softmax_w(x_w)\n",
    "        y = y+x_w_softmax\n",
    "            \n",
    "        for k in range(self.n_neighbors):\n",
    "            x_w = x * (1 - y)\n",
    "            x_w_softmax = self.softmax_w(x_w)\n",
    "            y = y+x_w_softmax\n",
    "            \n",
    "            dm=torch.matmul(t.T,x_w_softmax.T)\n",
    "            \n",
    "            if k == 0:\n",
    "                dn=dm\n",
    "            else:\n",
    "                dn=torch.cat((dn,dm))\n",
    "        return dn.T\n",
    "\n",
    "    def learn_metric(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        d=self.metric(x)\n",
    "        t=self.metric(self.training_datapoints)\n",
    "        return d,t\n",
    "    \n",
    "    def find_nearest_neighbors(self,x: torch.Tensor,t: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        dist = torch.cdist(x, t)\n",
    "        dist=torch.exp(-dist)\n",
    "        dn = self.soft_top_k(dist,t)\n",
    "        \n",
    "        return dn\n",
    "        \n",
    "    def encode(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x=self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x=self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode_decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        d,t=self.learn_metric(x)\n",
    "        dn=self.find_nearest_neighbors(d,t)\n",
    "        \n",
    "        s=self.encode(dn)\n",
    "        x_hat=self.decode(s) \n",
    "        \n",
    "        return x_hat,s,d,dn\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor :\n",
    "        d,t=self.learn_metric(x)\n",
    "        dn=self.find_nearest_neighbors(d,t)\n",
    "        s=self.encode(dn).reshape(-1,1)\n",
    "        z=self.compute_z(x).reshape(-1,1)\n",
    "        \n",
    "        out=torch.hstack((s,z))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def compute_z(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        z_dist=torch.cdist(x,self.training_datapoints_z)\n",
    "        z_dist=torch.absolute(z_dist)\n",
    "        z=(-1/self.z_lambda)*torch.log(torch.sum(torch.exp(-self.z_lambda*z_dist),axis=1))\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example usage\n",
    "\n",
    "ANN_architecture=[8]\n",
    "AutoEncoder_architecture=[24,16]\n",
    "\n",
    "n_features=2\n",
    "d_metric=3\n",
    "n_neighbors=3\n",
    "l=50\n",
    "\n",
    "model = DeepLNE_CV(ANN_layers=ANN_architecture,\n",
    "                   AutoEncoder_layers=AutoEncoder_architecture,\n",
    "                   f=n_features,\n",
    "                   d=d_metric,\n",
    "                   n=n_neighbors,\n",
    "                   ref=model_datapoints,\n",
    "                   ref_z=model_datapoints,\n",
    "                   act='Tanh',\n",
    "                   z_lambda=l)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d3ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example training\n",
    "track=[]\n",
    "best_loss=1e10\n",
    "\n",
    "num_epochs = 5001\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for data in training_batches:\n",
    "        x = data\n",
    "        \n",
    "        # Forward Pass\n",
    "        x_hat,s,d,dn = model.encode_decode(x)\n",
    "\n",
    "        # Compute Loss\n",
    "        loss = model.loss_mse(x_hat, x)\n",
    "\n",
    "        # Backward Pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(training_batches)\n",
    "    \n",
    "    track.append(train_loss)\n",
    "    \n",
    "    if epoch%100==0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        \n",
    "        if train_loss < best_loss:\n",
    "            best_loss=train_loss\n",
    "            filename = 'model.pth'\n",
    "            torch.save(model, filename)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example export to plumed \n",
    "\n",
    "model_params=torch.save(model.state_dict(), 'model_params.pt')\n",
    "\n",
    "model_datapoints_z=model.encode_decode(model_datapoints)[0].detach().numpy()\n",
    "\n",
    "training_datapoints=torch.Tensor(training_datapoints)\n",
    "model_datapoints=torch.Tensor(model_datapoints)\n",
    "model_datapoints_z=torch.Tensor(model_datapoints_z)\n",
    "\n",
    "plumed_model = DeepLNE_CV(ANN_layers=ANN_architecture,\n",
    "                   AutoEncoder_layers=AutoEncoder_architecture,\n",
    "                   f=n_features,\n",
    "                   d=d_metric,\n",
    "                   n=n_neighbors,\n",
    "                   ref=model_datapoints,\n",
    "                   ref_z=model_datapoints_z,\n",
    "                   act='Tanh',\n",
    "                   z_lambda=l)\n",
    "\n",
    "plumed_model.load_state_dict(torch.load('model_params.pt'), strict=False)\n",
    "\n",
    "m=torch.jit.trace(plumed_model,torch.ones(1,n_features))\n",
    "m.save('model.ptc')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f6837e3",
   "metadata": {},
   "source": [
    "#Example usage as bias in plumed.dat\n",
    "\n",
    "feature1:...\n",
    "feature2:...\n",
    "...\n",
    "\n",
    "model: PYTORCH_MODEL FILE=model.ptc ARG=feature1,feature2...\n",
    "\n",
    "opes: OPES_METAD ARG=model.node-0 BARRIER=... PACE=...\n",
    "\n",
    "uwall: UPPER_WALLS ARG=model.node-1 KAPPA=... AT=..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
